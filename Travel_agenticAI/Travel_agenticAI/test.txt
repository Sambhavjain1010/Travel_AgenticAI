agents
    input_parser.py

    # from models.llm_generator import build_llm
    from pydantic import BaseModel, Field
    from typing import Optional, Literal

    class TravelQuery (BaseModel):
        destination: str = Field(description="Place to travel, itenary will be prepared according to this")
        duration: Optional[int] = Field(description="The number of days for travel")
        traveler_type: Optional[Literal['family', 'couple', 'friends', 'solo']] = Field(description="The kind of people user is travelling with")
        interests: Optional[str] = Field(description="The kind of activities user is interested in.")
        budget: Optional[str] = Field(description="User's budget for the trip")
    
inputs
    prompt_input.py
    
    from langchain_core.prompts import PromptTemplate

    def build_prompt():
        prompt = PromptTemplate(
            template="""
            I'm planning a {duration} day trip to {destination} with {traveler_type} for a {interests} vacation.
            """,
            input_variables=['duration', 'destination', 'traveler_type', 'interests']
        )

        return prompt

models
    llm_generator.py

    from langchain_openai import AzureChatOpenAI
    from dotenv import load_dotenv
    import os

    load_dotenv()

    key = os.getenv("AZURE_OPENAI_API_KEY")
    endpoint = os.getenv("AZURE_OPENAI_API_ENDPOINT")
    version = os.getenv("AZURE_OPENAI_API_VERSION")

    def build_llm() :
        llm = AzureChatOpenAI (
            api_key=key,
            azure_endpoint=endpoint,
            api_version=version,
            deployment_name="gpt-4o",
            temperature=1
        )
        
        return llm

main.py

    import streamlit as st
    from inputs.prompt_input import build_prompt
    from agents.input_parser import TravelQuery
    from models.llm_generator import build_llm
    from langchain_core.output_parsers import StrOutputParser

    llm = build_llm()
    structured_model = llm.with_structured_output(TravelQuery)
    parser = StrOutputParser()
    prompt = build_prompt()

    input_text = st.text_input("Enter the Input")

    if input_text:
        with st.spinner("Generating your itenary......"):
            structured_result = structured_model.invoke(input_text)

            travel_dict = dict(structured_result)
            print(travel_dict['traveler_type'])
            print(structured_result)
            chain = prompt | llm | parser
            result = chain.invoke(travel_dict)

            st.markdown(result)